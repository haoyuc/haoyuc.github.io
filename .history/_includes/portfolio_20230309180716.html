<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

		

  <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/OrdinalCLIP.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal Regression</papertitle>
             <br>
       <strong>Wanhua Li*</strong>, Xiaoke Huang*, Zheng Zhu, Yansong Tang, Xiu Li, Jie Zhou, and Jiwen Lu

             <br>
             <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022
       <br>
             <a href="https://xk-huang.github.io/OrdinalCLIP/">[Website]</a> 
       <a href="https://arxiv.org/abs/2206.02338">[arxiv]</a> 
             <a href="https://github.com/xk-huang/OrdinalCLIP">[Code]</a>
       <a href="https://zhuanlan.zhihu.com/p/565034693">[中文解读]</a>
             <br>
             <p>We propose a language-powered paradigm for ordinal regression, which learns the rank concepts from the rich semantic CLIP latent space.</p>
           </td>
        </tr>
   
         <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/l2l.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Label2Label: A Language Modeling Framework for Multi-Attribute Learning</papertitle>
             <br>
       <strong>Wanhua Li</strong>, Zhexuan Cao, Jianjiang Feng, Jie Zhou, and Jiwen Lu
             <br>
             <em>European Conference on Computer Vision (ECCV)</em>, 2022
       <br>
             <a href="https://li-wanhua.github.io/Label2Label/">[Website]</a> 
       <a href="https://arxiv.org/pdf/2207.08677.pdf">[arxiv]</a> 
       <a href="https://www.youtube.com/watch?v=999znKklDb4">[Video]</a> 
             <a href="https://github.com/Li-Wanhua/Label2Label">[Code]</a>
             <br>
             <p> We propose a language modeling framework named Label2Label to model the complex instance-wise attribute relations, 
         which regards each attribute label as a “word” and recovers the label “sentence” based on the masked one.</p>
           </td>
        </tr>
   

   
         <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/talkinghead2.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Learning Dynamic Facial Radiance Fields for Few-Shot Talking Head Synthesis</papertitle>
             <br>
     Shuai Shen, <strong>Wanhua Li</strong>, Zheng Zhu, Yueqi Duan, Jie Zhou, and Jiwen Lu
             <br>
             <em>European Conference on Computer Vision (ECCV)</em>, 2022
       <br>
             <a href="https://sstzal.github.io/DFRF/">[Website]</a> 
       <a href="https://arxiv.org/abs/2207.11770">[arxiv]</a> 
       <a href="https://www.youtube.com/watch?v=F6fkVNk9bBw&amp;ab_channel=Shens">[Video]</a> 
             <a href="https://github.com/sstzal/DFRF">[Code]</a>
             <br>
             <p> We propose dynamic facial radiance fields conditioned on the 3D aware reference image features. 
         The facial field can rapidly generalize to novel identities with only 15s clip.</p>
           </td>
        </tr>
   
 <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/MetaAge.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>MetaAge: Meta-Learning Personalized Age Estimators</papertitle>
             <br>
      <strong>Wanhua Li</strong>, Jiwen Lu, Abudukelimu Wuerkaixi, Jianjiang Feng, and Jie Zhou
             <br>
             <em>IEEE Transactions on Image Processing</em>, 2022
       <br>
       <a href="https://li-wanhua.github.io/MetaAge/">[Website]</a> 
             <a href="https://ieeexplore.ieee.org/document/9826407">[Paper]</a> 
       <a href="http://arxiv.org/abs/2207.05288">[arxiv]</a> 
       <a href="https://github.com/Li-Wanhua/MetaAge">[Code]</a> 
             <br>
             <p> We propose a personalized age estimation method named MetaAge, which learns the mapping from identity information to age estimator parameters.</p>
           </td>
         </tr>
   
       
 <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/MRIN.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Learning Adaptive Patch Generators for Mask-Robust Image Inpainting</papertitle>
             <br>
       Hongyi Sun, <strong>Wanhua Li</strong>, Yueqi Duan, Jie Zhou, and Jiwen Lu
             <br>
             <em>IEEE Transactions on Multimedia</em>, 2022
       <br>
       <a href="https://ieeexplore.ieee.org/document/9773024">[Paper]</a>
       <a href="data/tmm22.txt">[bibtex]</a> 
             <br>
             <p> We propose a Mask-Robust Inpainting Network (MRIN) to recover the masked areas of an image with a patch-wise inpainting process.</p>
           </td>
         </tr>
   
   
 <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/HRGN.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Reasoning Graph Networks for Kinship Verification: from Star-shaped to Hierarchical</papertitle>
             <br>
       <strong>Wanhua Li</strong>, Jiwen Lu, Abudukelimu Wuerkaixi, Jianjiang Feng, and Jie Zhou
             <br>
             <em>IEEE Transactions on Image Processing</em>, 2021
       <br>
       <a href="https://ieeexplore.ieee.org/document/9426411">[Paper]</a>
       <a href="https://arxiv.org/pdf/2109.02219.pdf">[arxiv]</a>
       <a href="data/tip20_rgn.txt">[bibtex]</a> 
             <br>
             <p> We develop a Hierarchical Reasoning Graph Network (H-RGN) to exploit more powerful and flexible capacity for graph-based kinship verification.</p>
           </td>
         </tr>
      
   
 <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/FAST.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Frequency-Aware Spatiotemporal Transformers for Video Inpainting Detection</papertitle>
             <br>
       Bingyao Yu, <strong>Wanhua Li</strong>, Xiu Li, Jiwen Lu, and Jie Zhou
             <br>
             <em>IEEE International Conference on Computer Vision (ICCV)</em>, 2021
       <br>
             
       <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_Frequency-Aware_Spatiotemporal_Transformers_for_Video_Inpainting_Detection_ICCV_2021_paper.pdf">[Paper]</a> 
       <a href="data/iccv21.txt">[bibtex]</a> 
             <br>
             <p> We propose a Frequency-Aware Spatiotemporal Transformer for video inpainting detection, which simultaneously mines the traces of video inpainting from spatial, temporal, and frequency domains.</p>
           </td>
         </tr>
   
      <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/uncertainty_regression.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Learning Probabilistic Ordinal Embeddings for Uncertainty-Aware Regression</papertitle>
             <br>
       <strong>Wanhua Li</strong>, Xiaoke Huang, Jiwen Lu, Jianjiang Feng, and Jie Zhou
             <br>
             <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
       <br>
             <a href="https://li-wanhua.github.io/POEs/">[Website]</a> 
       <a href="https://arxiv.org/abs/2103.13629">[arxiv]</a> 
       <a href="https://www.youtube.com/watch?v=NCJZyvKZ8vc">[Video]</a> 
             <a href="https://github.com/Li-Wanhua/POEs">[Code]</a>
             <br>
             <p> We propose probabilistic ordinal embeddings to empower the present-day regression methods with the ability of uncertainty estimation.</p>
           </td>
         </tr>
   
     <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/DSMM.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Meta-Mining Discriminative Samples for Kinship Verification</papertitle>
             <br>
       <strong>Wanhua Li</strong>, Shiwei Wang, Jiwen Lu, Jianjiang Feng, and Jie Zhou
             <br>
             <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
       <br>
       <a href="https://li-wanhua.github.io/DSMM/">[Website]</a> 
             <a href="https://arxiv.org/abs/2103.15108">[arxiv]</a> 
       <a href="https://www.youtube.com/watch?v=gEQETp4hCAc">[Video]</a> 
             <a href="data/CVPR2021meta.txt">[bibtex]</a>
             <br>
             <p> A Discriminative Sample Meta-Mining strategy is proposed to mine discriminative information from limited positive pairs and sufficient negative samples for kinship verification. </p>
           </td>
         </tr>
   
 <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/STAR_FC.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Structure-Aware Face Clustering on a Large-Scale Graph with 10^7 Nodes</papertitle>
             <br>
       Shuai Shen, <strong>Wanhua Li</strong>, Zheng Zhu, Guan Huang, Dalong Du, Jiwen Lu, and Jie Zhou
             <br>
             <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
       <br>
             <a href="https://sstzal.github.io/STAR-FC/">[Website]</a> 
             <a href="https://arxiv.org/abs/2103.13225">[arxiv]</a> 
             <a href="https://github.com/sstzal/STAR-FC">[Code]</a>
       <a href="https://www.youtube.com/watch?v=VwAomM3wk6k">[Video]</a> 
             <br>
             <p> It is the first face clustering method to train on very large-scale graph with 20M nodes, and achieve superior inference results on 12M testing data.</p>
           </td>
         </tr>
   
     <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/social_graph.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Graph-Based Social Relation Reasoning</papertitle>
             <br>
       <strong>Wanhua Li</strong>, Yueqi Duan, Jiwen Lu, Jianjiang Feng, and Jie Zhou
             <br>
             <em>European Conference on Computer Vision (ECCV)</em>, 2020
       <br>
       <a href="https://li-wanhua.github.io/GR2N/">[Website]</a> 
             <a href="https://arxiv.org/abs/2007.07453">[arxiv]</a> 
       <a href="https://www.youtube.com/watch?v=zCTPRxxlZsI&amp;t=427s">[Video]</a> 
             <a href="https://github.com/Li-Wanhua/GR2N">[Code]</a>
             <br>
             <p> A simpler, faster, and more accurate method for social relation recognition.</p>
           </td>
         </tr>
 
   <!--
       <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src='images/graph_kinship.png' alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Graph-based Kinship Reasoning Network</papertitle>
             <br>
       <strong>Wanhua Li</strong>, Yingqiang Zhang, Kangchen Lv, Jiwen Lu, Jianjiang Feng, Jie Zhou
             <br>
             <em>IEEE International Conference on Multimedia and Expo (ICME)</em>, 2020
       <br>
       <font color="red"><strong>Oral Presentation</strong></font>
             <br>
             <a href="https://arxiv.org/abs/2004.10375">[arXiv]</a>  
       <a href="https://www.youtube.com/watch?v=QkMiKE30Lv4">[Video]</a> 
       <a href="data/icme20_graphkinship.txt">[bibtex]</a> 
             <br>
             <p> We considers how to compare and fuse the extracted feature pair to reason about the kin relations with the proposed graph-based kinship reasoning networks. </p>
           </td>
         </tr>
 -->	  
       <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/bridge.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>BridgeNet: A Continuity-Aware Probabilistic Network for Age Estimation</papertitle>
             <br>
       <strong>Wanhua Li</strong>, Jiwen Lu, Jianjiang Feng, Chunjing Xu, Jie Zhou, Qi Tian
             <br>
             <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019
             <br>
             <a href="https://arxiv.org/abs/1904.03358">[arXiv]</a>  
       <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_BridgeNet_A_Continuity-Aware_Probabilistic_Network_for_Age_Estimation_CVPR_2019_paper.pdf">[PDF]</a>  
       <a href="data/cvpr19_BridgeNet.txt">[bibtex]</a> 
             <br>
             <p> We propose BridgeNet for age estimation, which aims to mine the continuous relation between age labels effectively. </p>
           </td>
         </tr>

     

       </tbody></table>