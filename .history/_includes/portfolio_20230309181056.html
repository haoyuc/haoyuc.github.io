<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

		

  <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/OrdinalCLIP.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal Regression</papertitle>
             <br>
       <strong>Wanhua Li*</strong>, Xiaoke Huang*, Zheng Zhu, Yansong Tang, Xiu Li, Jie Zhou, and Jiwen Lu

             <br>
             <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022
       <br>
             <a href="https://xk-huang.github.io/OrdinalCLIP/">[Website]</a> 
       <a href="https://arxiv.org/abs/2206.02338">[arxiv]</a> 
             <a href="https://github.com/xk-huang/OrdinalCLIP">[Code]</a>
       <a href="https://zhuanlan.zhihu.com/p/565034693">[中文解读]</a>
             <br>
             <p>We propose a language-powered paradigm for ordinal regression, which learns the rank concepts from the rich semantic CLIP latent space.</p>
           </td>
        </tr>
   
         <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="images/l2l.png" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Label2Label: A Language Modeling Framework for Multi-Attribute Learning</papertitle>
             <br>
       <strong>Wanhua Li</strong>, Zhexuan Cao, Jianjiang Feng, Jie Zhou, and Jiwen Lu
             <br>
             <em>European Conference on Computer Vision (ECCV)</em>, 2022
       <br>
             <a href="https://li-wanhua.github.io/Label2Label/">[Website]</a> 
       <a href="https://arxiv.org/pdf/2207.08677.pdf">[arxiv]</a> 
       <a href="https://www.youtube.com/watch?v=999znKklDb4">[Video]</a> 
             <a href="https://github.com/Li-Wanhua/Label2Label">[Code]</a>
             <br>
             <p> We propose a language modeling framework named Label2Label to model the complex instance-wise attribute relations, 
         which regards each attribute label as a “word” and recovers the label “sentence” based on the masked one.</p>
           </td>
        </tr>
   

   
         <tr>
           <td style="padding:20px;width:30%;max-width:30%" align="center">
             <img style="width:100%;max-width:100%" src="../assets/img/SRP.jpg" alt="dise">
           </td>
           <td width="75%" valign="center">
             <papertitle>Super-resolution perception for industrial sensor data</papertitle>
             <br>
             Jinjin Gu, <strong>Haoyu Chen</strong>, Guolong Liu, Gaoqi Liang, Xinlei Wang, Junhua Zhao             
             <br>
             <em>arXiv</em>, 2018
       <br>
             <a href="https://sstzal.github.io/DFRF/">[Website]</a> 
       <a href="https://arxiv.org/abs/2207.11770">[arxiv]</a> 
       <a href="https://www.youtube.com/watch?v=F6fkVNk9bBw&amp;ab_channel=Shens">[Video]</a> 
             <a href="https://github.com/sstzal/DFRF">[Code]</a>
             <br>
             <p> We propose dynamic facial radiance fields conditioned on the 3D aware reference image features. 
         The facial field can rapidly generalize to novel identities with only 15s clip.</p>
           </td>
        </tr>
  

     

       </tbody></table>