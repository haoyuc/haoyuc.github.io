---
layout: about 
---

<br/>




<!--# Bio

I received a Bachelor degree in Computer Science and Engineering at The Chinese University of Hong Kong, Shenzhen (CUHKSZ) in 2021.    
I am a Ph.D. student at the Hong Kong University of Science and Technology (Guangzhou) advised by [Prof. Lei Zhu](https://sites.google.com/site/indexlzhu/home).   
Mainly intrest in computer vision, especially in **Low-level Vision**.

[Google Scholar](https://scholar.google.com/citations?&user=KWbcBucAAAAJ) &nbsp;&nbsp;&nbsp;
[GitHub](https://github.com/haoyuc) &nbsp;&nbsp;&nbsp;
[Email](mailto:hchen794@connect.hkust-gz.edu.cn)

-->



<style>
  /* 全局样式 */
  body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    line-height: 1.6;
    color: #333;
    background-color: #fff;
  }
  
  h1, h2, h3, h4, h5 {
    font-weight: 600;
    margin-top: 1.5em;
    margin-bottom: 0.8em;
    color: #293845;
  }
  
  h1 {
    font-size: 1.8em;
  }
  
  a {
    color: #0070c9;
    text-decoration: none;
    transition: color 0.2s ease;
  }
  
  a:hover {
    color: #005ba4;
    text-decoration: underline;
  }
  
  /* 容器样式 */
  main,
  footer,
  .nav-container {
    display: block;
    margin: 0 auto;
    max-width: 800px;
    width: 80%;
  }
  
  /* 纸牌布局样式 */
  .card {
    background: #fff;
    border-radius: 8px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    padding: 20px;
    margin-bottom: 20px;
    transition: transform 0.2s ease, box-shadow 0.2s ease;
  }
  
  .card:hover {
    box-shadow: 0 4px 15px rgba(0,0,0,0.08);
    transform: translateY(-2px);
  }
  
  /* 链接动画效果 */
  @keyframes link-focus {
    0% { opacity: 1; }
    50% { opacity: 0.7; transform: scale(1.03); }
    100% { opacity: 1; }
  }
  
  .link-effect:hover {
    animation: link-focus 0.5s forwards;
  }
  
  /* 图片样式 */
  .image-wrapper img {
    border-radius: 4px;
    transition: all 0.3s ease;
  }
  
  /* 论文标题样式 */
  .paper-title {
    font-weight: 600;
    font-size: 1.05em;
    margin: 6px 0;
    color: #293845;
    line-height: 1.4;
  }
  
  /* 作者样式 */
  .author {
    font-size: 0.95em;
    margin-bottom: 6px;
    color: #555;
  }
  
  .author-me {
    font-weight: 600;
    color: #0070c9;
  }
  
  /* 分隔线样式 */
  hr {
    border: none;
    height: 1px;
    background-color: #eee;
    margin: 2em 0;
  }
  
  /* 响应式布局 */
  @media (max-width: 768px) {
    .flex-container {
      flex-direction: column;
    }
    
    .left-column, .right-column {
      width: 100%;
      padding: 0;
    }
  }
</style>


<style>
  @keyframes blink {
    0% {
      opacity: 1;
    }
    50% {
      opacity: 0.5;
      transform: scale(1.1);
    }
    100% {
      opacity: 1;
    }
  }

  a:hover {
    animation: blink 1s forwards;
    /* color: red; */
    /* text-shadow: 0 0 4px yellow; */
  }
</style>


<div class="flex-container" style="display: flex; padding-top:30px; padding-bottom:20px; flex-wrap: wrap; gap: 30px;">

  <!-- 左侧个人信息 -->
  <div class="left-column" style="flex: 1; min-width:180px; max-width:250px;">
    <div class="profile-card" style="border-radius:8px; overflow:hidden; box-shadow:0 4px 12px rgba(0,0,0,0.08);">
      <img src="../assets/img/IMG_6589.JPG" alt="Haoyu Chen" style="width:100%; height:auto; display:block;">
    </div>
    
    <div class="contact-links" style="margin-top:25px;">
      <div class="contact-item" style="display:flex; align-items:center; margin-bottom:15px;">
        <img src="../assets/img/email.svg" width="18px" height="18px" style="margin-right:12px;">
        <a href="mailto:hchen794@connect.hkust-gz.edu.cn" class="link-effect" style="color:#333; font-size:0.9em;">E-mail</a>
      </div>
      
      <div class="contact-item" style="display:flex; align-items:center; margin-bottom:15px;">
        <img src="../assets/img/google_scholar.png" width="18px" height="18px" style="margin-right:12px;">
        <a href="https://scholar.google.com/citations?user=KWbcBucAAAAJ" class="link-effect" style="color:#333; font-size:0.9em;">Google Scholar</a>
      </div>
      
      <div class="contact-item" style="display:flex; align-items:center; margin-bottom:15px;">
        <img src="../assets/img/github.svg" width="18px" height="18px" style="margin-right:12px;">
        <a href="https://github.com/haoyuc" class="link-effect" style="color:#333; font-size:0.9em;">GitHub</a>
      </div>
      
      <div class="contact-item" style="display:flex; align-items:center; margin-bottom:15px;">
        <img src="../assets/img/wechat.svg" width="18px" height="18px" style="margin-right:12px;">
        <span class="tooltip-trigger" style="color:#333; font-size:0.9em; cursor:pointer;" onmouseover="showTooltip(event, 'Feel free to contact me.')" onmouseout="hideTooltip()">WeChat: @haoyuc98</span>
      </div>
    </div>
    
    <div id="tooltip" style="display: none; position: absolute; background-color: #fff; border: 1px solid #eee; padding: 8px 12px; border-radius: 6px; box-shadow: 0 4px 10px rgba(0,0,0,0.1); font-size: 0.8em; z-index: 100; max-width: 200px;"></div>
  </div>

  <!-- 右侧内容 -->
  <div class="right-column" style="flex: 2.5; min-width:300px;">
    <h1 style="margin-top:0; margin-bottom:5px; font-size:2em; color:#293845;">陈浩宇 Haoyu Chen</h1>
    <p style="color:#0070c9; margin-top:0; font-size:1.1em; margin-bottom:25px;">PhD student @ HKUST(GZ)</p>
    
    <div class="bio-section">
      <p style="margin-top:0;">我于2021年获得香港中文大学（深圳）计算机科学与工程专业学士学位。</p>
      <p>目前是香港科技大学（广州）的博士生，导师为<a href="https://sites.google.com/site/indexlzhu/home?authuser=0">朱雷教授</a>和<a href="https://scholar.google.com/citations?user=XhyKVFMAAAAJ&hl=en">谭平教授</a>。</p>
      <p>主要研究领域为计算机视觉，特别是低层次视觉、图像处理、多模态模型和生成模型。</p>
    </div>
  </div>

</div>

<script>
  function showTooltip(event, text) {
    var tooltip = document.getElementById('tooltip');
    tooltip.innerHTML = text;
    tooltip.style.left = (event.pageX + 10) + 'px';
    tooltip.style.top = (event.pageY + 10) + 'px';
    tooltip.style.display = 'block';
  }

  function hideTooltip() {
    var tooltip = document.getElementById('tooltip');
    tooltip.style.display = 'none';
  }
</script>

<hr style="border:none; height:1px; background-color:#f0f0f0; margin:20px 0 30px 0;">

<h2 style="color:#293845; font-size:1.6em; border-left:4px solid #0070c9; padding-left:10px; margin-top:40px; margin-bottom:25px;">发表论文 Publications</h2>

<div class="category-header" style="display:flex; align-items:center; margin-bottom:20px; background:#f0f5fa; border-radius:6px; padding:12px 16px;">
  <div style="width:6px; height:20px; background:#0070c9; margin-right:10px; border-radius:3px;"></div>
  <h3 style="margin:0; font-size:1.2em; color:#293845;">生成模型与人工智能内容生成 (Generative Models and AIGC)</h3>
</div>

<div class="publications-container" style="margin-bottom:30px;">

<div class="publication-item" style="display:flex; flex-wrap:wrap; margin-bottom:30px; background:#fff; border-radius:8px; box-shadow:0 2px 10px rgba(0,0,0,0.05); overflow:hidden; transition:transform 0.2s ease, box-shadow 0.2s ease;">
  <div class="pub-image" style="flex:1; min-width:200px; max-width:280px; overflow:hidden;">
    <img src="../assets/img/POSTA.jpg" alt="POSTA" style="width:100%; height:auto; object-fit:cover; transition:transform 0.3s ease;" onmouseover="this.style.transform='scale(1.03)'" onmouseout="this.style.transform='scale(1)'">
  </div>
  
  <div class="pub-info" style="flex:2; min-width:300px; padding:20px;">
    <div style="display:inline-block; background:#f0f5fa; color:#0070c9; font-size:0.8em; padding:4px 8px; border-radius:4px; margin-bottom:10px;">CVPR 2025</div>
    
    <h3 style="margin:0 0 10px 0; font-size:1.2em; color:#293845; line-height:1.4;">POSTA: 定制艺术海报生成的通用框架</h3>
    <p style="margin:0 0 12px 0; color:#666; font-size:0.9em;">POSTA: A Go-to Framework for Customized Artistic Poster Generation</p>
    
    <p style="margin:0 0 15px 0; color:#444; font-size:0.9em;">
      <span style="color:#0070c9; font-weight:500;">陈浩宇*</span>, 徐小杰*, 李文博, 任晶晶, 叶天, 刘松华, 陈颖聪, 朱雷, 王鑫超
    </p>
    
    <div class="pub-links" style="margin-top:15px;">
      <a href="https://haoyuchen.com/POSTA" class="pub-button" style="display:inline-block; background:#0070c9; color:white; padding:6px 12px; border-radius:4px; font-size:0.85em; margin-right:8px; text-decoration:none; transition:background 0.2s ease;" onmouseover="this.style.background='#005ba4'" onmouseout="this.style.background='#0070c9'">项目主页</a>
      
      <a href="https://arxiv.org/abs/2503.14908" class="pub-button" style="display:inline-block; background:#f5f5f5; color:#333; padding:6px 12px; border-radius:4px; font-size:0.85em; margin-right:8px; text-decoration:none; transition:background 0.2s ease;" onmouseover="this.style.background='#e8e8e8'" onmouseout="this.style.background='#f5f5f5'">论文</a>
    </div>
  </div>
</div>








<!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/UltraPixel.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">NeurIPS, 2024</div>
      <div  class="paper-title">
        UltraPixel: Advancing Ultra-High-Resolution Image Synthesis to New Peaks
      </div>
      <div class="author">
      Jingjing Ren*, Wenbo Li*, <span class="author-me">Haoyu Chen</span>, Renjing Pei, Bin Shao, Yong Guo, Long Peng, Lei Zhu
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
     <!-- <br> -->
      <a href="https://jingjingrenabc.github.io/ultrapixel/">[Website]</a> 
      <a href="https://arxiv.org/abs/2407.02158">[arxiv]</a> 
      <a href="https://github.com/catcathh/UltraPixel">[Code]</a>
      <a href="https://huggingface.co/spaces/roubaofeipi/UltraPixel-demo">[Demo]</a> 
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
      <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->



<!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/face1.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">arXiv, 2023</div>
      <div  class="paper-title">
        Towards Flexible, Scalable, and Adaptive Multi-Modal Conditioned Face Synthesis
      </div>
      <div class="author">
      Jingjing Ren, Cheng Xu, <span class="author-me">Haoyu Chen</span>, Xinran Qin, Chongyi Li, Lei Zhu
      </div>
      <div  style="font-size: 12px;!important">
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
      <a href="https://jingjingrenabc.github.io/multimodal-face-synthesis/">[Website]</a> 
      <a href="https://arxiv.org/abs/2312.16274">[arxiv]</a> 
      <!-- <a href="">[Code]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
      </div>
      <!-- <br> -->
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->




    </tbody>
</table>
<hr style="border-top: 1px solid #f0f0f0; margin-top: 25px; margin-bottom:25px;">








<span style="font-weight:600;font-size:17px;"> 
&nbsp;&nbsp;  Multi-Modal Models and Agents
</span>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>





<!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/restoreagent.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">NeurIPS, 2024</div>
      <div  class="paper-title">
        RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models
      </div>
      <div class="author">
      <span class="author-me">Haoyu Chen</span>, Wenbo Li, Jinjin Gu, Jingjing Ren, Sixiang Chen, Tian Ye, Renjing Pei, Kaiwen Zhou, Fenglong Song, Lei Zhu
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
     <!-- <br> -->
      <a href="https://haoyuchen.com/RestoreAgent">[Website]</a> 
      <a href="https://arxiv.org/abs/2407.18035">[arxiv]</a> 
      <!-- <a href="https://github.com/catcathh/UltraPixel">[Code]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
      <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->






<!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/JarvisIR.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">CVPR, 2025</div>
      <div  class="paper-title">
        JarvisIR: Elevating Autonomous Driving Perception with Intelligent Image Restoration
      </div>
      <div class="author">
      Yunlong Lin*, Zixu Lin*, <span class="author-me">Haoyu Chen*</span>, Panwang Pan*,  Chenxin Li, Sixiang Chen, Kairun Wen, Yeying Jin, Wenbo Li, Xinghao Ding
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
     <!-- <br> -->
      <!-- <a href="https://haoyuchen.com/RestoreAgent">[Website]</a>  -->
      <!-- <a href="https://arxiv.org/abs/2407.18035">[arxiv]</a>  -->
      <!-- <a href="https://github.com/catcathh/UltraPixel">[Code]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
      <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->






    </tbody>
</table>
<hr style="border-top: 1px solid #f0f0f0; margin-top: 25px; margin-bottom:25px;">






<span style="font-weight:600;font-size:17px;"> 
&nbsp;&nbsp;  Generalizable Image Restoration
</span>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



<!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/cvpr24.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">CVPR, 2024</div>
      <div  class="paper-title">
        Low-Res Leads the Way: Improving Generalization for Super-Resolution by Self-Supervised Learning
      </div>
      <div class="author">
      <span class="author-me">Haoyu Chen</span>, Wenbo Li, Jinjin Gu, Jingjing Ren, Haoze Sun, Xueyi Zou, Youliang Yan, Zhensong Zhang, Lei Zhu
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
     <!-- <br> -->
      <a href="https://haoyuchen.com/LWay">[Website]</a> 
      <a href="https://arxiv.org/abs/2403.02601">[arxiv]</a> 
      <!-- <a href="">[Code]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
      <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->





  <!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/mask.jpg" alt="dise">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">CVPR, 2023</div>
      <div  class="paper-title">
        Masked Image Training for Generalizable Deep Image Denoising
      </div>
      <div class="author">
      <span class="author-me">Haoyu Chen*</span>, Jinjin Gu*, Yihao Liu, Salma Abdel Magid, Chao Dong, Qiong Wang, Hanspeter Pfister, Lei Zhu
      </div>
      <!-- <em>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></em>, 2023 -->
      <!-- <br> -->
      <!-- <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a>  -->
      <a href="https://arxiv.org/abs/2303.13132">[arxiv]</a> 
      <a href="https://github.com/haoyuc/MaskedDenoising">[Code]</a>
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
  <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->



<!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/coser.png" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">CVPR, 2024</div>
      <div  class="paper-title">
        CoSeR: Bridging Image and Language for Cognitive Super-Resolution
      </div>
      <div class="author">
      Haoze Sun, Wenbo Li, Jianzhuang Liu, <span class="author-me">Haoyu Chen</span>, Renjing Pei, Xueyi Zou, Youliang Yan, Yujiu Yang
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
     <!-- <br> -->
      <a href="https://coser-main.github.io/">[Website]</a> 
      <a href="https://arxiv.org/abs/2311.16512">[arxiv]</a> 
      <a href="https://github.com/TianheWu/CoSeR">[Code]</a>
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
      <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->




  <!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/icml23.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">ICML, 2023</div>
      <div  class="paper-title">
        Crafting Training Degradation Distribution for the Accuracy-Generalization Trade-off in Real-World Super-Resolution
      </div>
      <div class="author">
      Ruofan Zhang, Jinjin Gu, <span class="author-me">Haoyu Chen</span>, Chao Dong, Yulun Zhang, Wenming Yang
      </div>
      <!-- <em>International Conference on Machine Learning <strong>(ICML)</strong></em>, 2023 -->
      <!-- <br> -->
      <!-- <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a>  -->
      <a href="https://arxiv.org/abs/2305.18107">[arxiv]</a> 
      <a href="">[Code]</a>
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
  <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->




  




  <!-- =================================================================================== -->
  <tr>
    <td style="padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/AAN.jpg" alt="dise">
    </td>
    <td width="75%" valign="center"  class="text-wrapper">
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">arXiv, 2021</div>
      <div  class="paper-title">
        Attention in Attention Network for Image Super-Resolution
      </div>
      <div class="author">
      <span class="author-me">Haoyu Chen</span>, Jinjin Gu, Zhi Zhang
      </div>
      <!-- <em>arXiv</em>, 2021 -->
      <!-- <br> -->
      <!-- <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a>  -->
      <a href="https://arxiv.org/abs/2104.09497">[arxiv]</a> 
      <a href="https://github.com/haoyuc/A2N">[Code]</a>
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
  <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->



  <!-- =================================================================================== -->
  <tr>
      <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
        <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/PIPAL.jpg" alt="dise">
      </td>
      <td width="75%" valign="center" class="text-wrapper">
        <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">ECCV, 2020</div>
        <div  class="paper-title">
          PIPAL: a Large-Scale Image Quality Assessment Dataset for Perceptual Image Restoration
        </div>
      <div class="author">
        Jinjin Gu, Haoming Cai, <span class="author-me">Haoyu Chen</span>, Xiaoxin Ye, Jimmy S.Ren, Chao Dong
      </div>
        <!-- <em>European Conference on Computer Vision  <strong>(ECCV)</strong></em>, 2020 -->
        <!-- <br> -->
        <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a> 
        <a href="https://arxiv.org/abs/2007.12142">[arxiv]</a> 
        <a href="https://github.com/HaomingCai/PIPAL-Codebase">[Code]</a>
        <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a> 
        <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a> 
        <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a> 
        <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a> 
    <br>
        <!-- <p> 
            We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
        </p> -->
      </td>
  </tr>
  <!-- =================================================================================== -->



    
    </tbody>
</table>
<hr style="border-top: 1px solid #f0f0f0; margin-top: 25px; margin-bottom:25px;">
<span style="font-weight:600;font-size:17px;"> 
&nbsp;&nbsp;  Adverse Weather Restoration
</span>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




  <!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/desnow.gif" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">ICCV, 2023</div>
      <div  class="paper-title">
        Snow Removal in Video: A New Dataset and A Novel Method
      </div>
      <div class="author">
      <span class="author-me">Haoyu Chen</span>, Jingjing Ren, Jinjin Gu, Hongtao Wu, Xuequan Lu, Haoming Cai, Lei Zhu
      </div>
      <!-- <em>International Conference on Computer Vision <strong>(ICCV)</strong></em>, 2023 -->
      <!-- <br> -->
      <!-- <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a>  -->
      <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.html">[arxiv]</a> 
      <a href="https://github.com/haoyuc/VideoDesnowing">[Code]</a>
      <a href="https://haoyuchen.com/VideoDesnowing">[Dataset]</a>
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
  <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->




  <!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/ijcv.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">IJCV, 2024</div>
      <div  class="paper-title">
        Triplane-Smoothed Video Dehazing with CLIP-Enhanced Generalization
      </div>
      <div class="author">
      Jingjing Ren, <span class="author-me">Haoyu Chen</span>, Tian Ye, Hongtao Wu, Lei Zhu
      </div>
      <!-- <em>International Conference on Computer Vision <strong>(ICCV)</strong></em>, 2023 -->
      <!-- <br> -->
      <!-- <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a>  -->
      <a href="https://link.springer.com/article/10.1007/s11263-024-02161-0">[paper]</a> 
      <!-- <a href="https://github.com/haoyuc/VideoDesnowing">[Code]</a> -->
      <!-- <a href="https://haoyuchen.com/VideoDesnowing">[Dataset]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
  <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->






<!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/eccv24.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">ECCV, 2024</div>
      <div  class="paper-title">
        Semi-Supervised Video Desnowing Network via Temporal Decoupling Experts and Distribution-Driven Contrastive Regularization
      </div>
      <div class="author">
      Hongtao Wu, Yijun Yang, Angelica Aviles-Rivero, Jingjing Ren, Sixiang Chen, <span class="author-me">Haoyu Chen</span>, Lei Zhu
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
     <!-- <br> -->
      <!-- <a href="https://haoyuchen.com/LWay">[Website]</a>  -->
      <!-- <a href="https://arxiv.org/abs/2403.02601">[arxiv]</a>  -->
      <!-- <a href="">[Code]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
      <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->




  <!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/mm1.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">ACM MM, 2023</div>
      <div  class="paper-title">
        Mask-Guided Progressive Network for Joint Raindrop and Rain Streak Removal in Videos
      </div>
      <div class="author">
      Hongtao Wu, Yijun Yang, <span class="author-me">Haoyu Chen</span>, Jingjing Ren, Lei Zhu
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
     <!-- <br> -->
      <!-- <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a>  -->
      <a href="https://dl.acm.org/doi/pdf/10.1145/3581783.3612001">[paper]</a> 
      <!-- <a href="">[Code]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
      <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->

    

  <!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/mm2.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">ACM MM, 2023</div>
      <div  class="paper-title">
        Uncertainty-Driven Dynamic Degradation Perceiving and Background Modeling for Efficient Single Image Desnowing
      </div>
      <div class="author">
      Sixiang Chen*, Tian Ye*, Chenghao Xue, <span class="author-me">Haoyu Chen</span>, Yun Liu, Erkang Chen, Lei Zhu
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
      <!-- <br> -->
      <!-- <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a>  -->
      <a href="https://dl.acm.org/pdf/10.1145/3581783.3612003">[paper]</a> 
      <!-- <a href="">[Code]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
  <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->





  <!-- =================================================================================== -->
  <tr>
    <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
      <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/mm3.jpg" alt="">
    </td>
    <td width="75%" valign="center" class="text-wrapper"> 
      <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">ACM MM, 2023</div>
      <div  class="paper-title">
        Cross-scale Prototype Learning Transformer for Image Snow Removal
      </div>
      <div class="author">
      Sixiang Chen*, Tian Ye*, Yun Liu, Jinbin Bai, <span class="author-me">Haoyu Chen</span>, Yunlong Lin, Jun Shi, Erkang Chen
      </div>
      <!-- <em>ACM Multimedia <strong>(ACM MM)</strong></em>, 2023 -->
    <!-- <br> -->
      <!-- <a href="https://www.jasongt.com/projectpages/pipal.html">[Website]</a>  -->
      <a href="https://dl.acm.org/doi/pdf/10.1145/3581783.3611893">[paper]</a> 
      <!-- <a href="">[Code]</a> -->
      <!-- <a href="https://paperswithcode.com/dataset/pipal-perceptual-iqa-dataset">[Benchmark]</a>  -->
      <!-- <a href="https://www.jasongt.com/research-full">[CVPR 2022 NTIRE Challenge]</a>  -->
      <!-- <a href="https://www.youtube.com/watch?v=315Umwgpa6s">[Youtube]</a>  -->
      <!-- <a href="https://www.bilibili.com/video/BV1cr4y1P7s4">[Bilibili]</a>  -->
  <br>
      <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
      </p> -->
    </td>
</tr>
<!-- =================================================================================== -->




    
    </tbody>
</table>
<hr style="border-top: 1px solid #f0f0f0; margin-top: 25px;margin-bottom:25px; ">
<span style="font-weight:600;font-size:17px;"> 
&nbsp;&nbsp;  Other
</span>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




  <!-- =================================================================================== -->
  <tr>
        <td style="margin:5px;padding:5px;width:30%;max-width:30%" align="center" class="image-wrapper">
          <img style="margin:5px;padding-right:20px;width:100%;max-width:100%;" src="../assets/img/SRP.jpg" alt="dise">
        </td>
        <td width="75%" valign="center"  class="text-wrapper">
        <div style="color: rgb(118, 130, 150); font-size: 0.9em; line-height: 1.3;">arXiv, 2018</div>
        <div  class="paper-title">
        Super-resolution perception for industrial sensor data
      </div>
      <div class="author">
        Jinjin Gu, <span class="author-me">Haoyu Chen</span>, Guolong Liu, Gaoqi Liang, Xinlei Wang, Junhua Zhao             
      </div>
        <!-- <em>arXiv</em>, 2018 -->
        <!-- <br> -->
        <!-- <a href="https://sstzal.github.io/DFRF/">[Website]</a>  -->
        <a href="https://arxiv.org/abs/1809.06687">[arxiv]</a> 
        <!-- <a href="https://www.youtube.com/watch?v=F6fkVNk9bBw&amp;ab_channel=Shens">[Video]</a>  -->
        <!-- <a href="https://github.com/sstzal/DFRF">[Code]</a> -->
        <br>
        <!-- <p> 
          We propose a novel machine learning problem – the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. 
        </p> -->
      </td>
  </tr>
    <!-- =================================================================================== -->


    </tbody>
</table>


<p style="padding:6px;"> </p>




# Experience 


<p style="margin-bottom: 20px;"></p>

<h2 style="color:#293845; font-size:1.6em; border-left:4px solid #0070c9; padding-left:10px; margin-top:40px; margin-bottom:25px;">工作经历 Experience</h2>

<div class="experience-section">
  <div class="experience-item" style="display:flex; align-items:flex-start; margin-bottom:25px; background:#f9f9f9; border-radius:8px; padding:20px;">
    <div style="margin-right:20px; padding-top:5px;">
      <img src="../assets/img/xiaobing.png" width="50px" height="50px" style="border-radius:4px;">
    </div>
    <div>
      <h3 style="margin:0 0 8px 0; font-size:1.2em; color:#293845;">小冰人工智能 Xiaobing.AI</h3>
      <p style="margin:0 0 5px 0; color:#0070c9; font-size:0.9em;">2021.6 - 2022.2 研究实习生</p>
      <p style="margin:0; color:#666; font-size:0.9em;">导师：<a href="https://scholar.google.com.hk/citations?user=OWa5rOEAAAAJ" target="_blank">王宝元博士</a></p>
    </div>
  </div>
  
  <div class="experience-item" style="display:flex; align-items:flex-start; margin-bottom:25px; background:#f9f9f9; border-radius:8px; padding:20px;">
    <div style="margin-right:20px; padding-top:5px;">
      <img src="../assets/img/aws.png" width="50px" height="50px" style="border-radius:4px;">
    </div>
    <div>
      <h3 style="margin:0 0 8px 0; font-size:1.2em; color:#293845;">亚马逊AWS上海AI实验室</h3>
      <p style="margin:0 0 5px 0; color:#0070c9; font-size:0.9em;">2020.5 - 2020.11 软件开发工程师实习生</p>
      <p style="margin:0; color:#666; font-size:0.9em;">导师：<a href="https://scholar.google.com.hk/citations?user=nZr0oXQAAAAJ" target="_blank">张志博士</a></p>
    </div>
  </div>
</div>



# Academic Service & Awards

<h2 style="color:#293845; font-size:1.6em; border-left:4px solid #0070c9; padding-left:10px; margin-top:40px; margin-bottom:25px;">学术服务与奖项 Academic Service & Awards</h2>

<div class="academic-section" style="display:flex; flex-wrap:wrap; gap:30px; margin-bottom:40px;">
  <div class="academic-card" style="flex:1; min-width:300px; background:#f9f9f9; border-radius:8px; padding:20px;">
    <h3 style="margin:0 0 15px 0; font-size:1.1em; color:#293845; border-bottom:2px solid #0070c9; padding-bottom:8px; display:inline-block;">竞赛获奖</h3>
    
    <ul style="padding-left:20px; margin:0; color:#555; font-size:0.95em;">
      <li style="margin-bottom:8px;">IEEE ICDM 2018全球AI气象挑战赛，<span style="color:#0070c9; font-weight:500;">第一名</span></li>
      <li style="margin-bottom:8px;">ECCV 2020 Workshop, AIM 2020极限超分辨率挑战赛，<span style="color:#0070c9; font-weight:500;">第四名</span></li>
    </ul>
  </div>
  
  <div class="academic-card" style="flex:1; min-width:300px; background:#f9f9f9; border-radius:8px; padding:20px;">
    <h3 style="margin:0 0 15px 0; font-size:1.1em; color:#293845; border-bottom:2px solid #0070c9; padding-bottom:8px; display:inline-block;">程序委员会/审稿人</h3>
    
    <ul style="padding-left:0; list-style-type:none; margin:0; color:#555; font-size:0.95em;">
      <li style="margin-bottom:6px;">IEEE计算机视觉与模式识别会议 <span style="color:#0070c9;">(CVPR)</span>, 2024</li>
      <li style="margin-bottom:6px;">欧洲计算机视觉会议 <span style="color:#0070c9;">(ECCV)</span>, 2024</li>
      <li style="margin-bottom:6px;">国际学习表示会议 <span style="color:#0070c9;">(ICLR)</span>, 2025</li>
      <li style="margin-bottom:6px;">ACM多媒体会议 <span style="color:#0070c9;">(ACM MM)</span>, 2023, 2024</li>
      <li style="margin-bottom:6px;">ACM SIGKDD数据挖掘会议 <span style="color:#0070c9;">(KDD)</span>, 2023</li>
      <li style="margin-bottom:6px;">SIAM数据挖掘国际会议 <span style="color:#0070c9;">(SDM)</span>, 2024</li>
      <li style="margin-bottom:6px;">计算机视觉应用冬季会议 <span style="color:#0070c9;">(WACV)</span>, 2023, 2024</li>
      <li style="margin-bottom:6px;">ACM SIGGRAPH VRCAI, 2022</li>
      <li style="margin-bottom:6px;">IEEE电路与系统视频技术汇刊</li>
      <li style="margin-bottom:6px;">IEEE移动计算汇刊</li>
      <li style="margin-bottom:6px;">计算机视觉期刊</li>
    </ul>
  </div>
</div>



# Hobbies & Interests
<h2 style="color:#293845; font-size:1.6em; border-left:4px solid #0070c9; padding-left:10px; margin-top:40px; margin-bottom:25px;">兴趣爱好 Hobbies & Interests</h2>

<div class="hobbies-section" style="display:flex; flex-wrap:wrap; gap:20px; margin-bottom:40px;">
  <div class="hobby-card" style="display:flex; align-items:center; background:#f9f9f9; border-radius:8px; padding:15px; min-width:130px;">
    <img src="../assets/img/outdoor2.png" width="24px" height="24px" style="margin-right:12px;">
    <span style="color:#293845; font-size:1em;">户外活动</span>
  </div>
  
  <div class="hobby-card" style="display:flex; align-items:center; background:#f9f9f9; border-radius:8px; padding:15px; min-width:130px;">
    <img src="../assets/img/travel1.png" width="24px" height="24px" style="margin-right:12px;">
    <span style="color:#293845; font-size:1em;">旅行</span>
  </div>
  
  <div class="hobby-card" style="display:flex; align-items:center; background:#f9f9f9; border-radius:8px; padding:15px; min-width:130px;">
    <img src="../assets/img/tennis.png" width="24px" height="24px" style="margin-right:12px;">
    <span style="color:#293845; font-size:1em;">网球</span>
  </div>
  
  <div class="hobby-card" style="display:flex; align-items:center; background:#f9f9f9; border-radius:8px; padding:15px; min-width:130px;">
    <img src="../assets/img/music.svg" width="24px" height="24px" style="margin-right:12px;">
    <span style="color:#293845; font-size:1em;">音乐</span>
  </div>
</div>






<!--# Publications

Please refer to my [Publication](https://haoyuchen.com/portfolio/) or [Google Scholar](https://scholar.google.com/citations?&user=KWbcBucAAAAJ).

-->