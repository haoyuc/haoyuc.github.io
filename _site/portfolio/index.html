<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Portfolio</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" type="text/css" href="/assets/css/fontawesome-all.min.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon.ico">

  <!-- Google Analytics -->
  

</head>


  <body>
    <!-- <nav class="nav">
      <div class="nav-container">
        <a href="/">
          <h2 class="nav-title">Haoyu Chen</h2>
        </a>
        <ul>
          <li><a href="/">About</a></li>
          <li><a href="/portfolio/">Publication</a></li>
        </ul>
     </div>
   </nav> -->

    <main>
      <div class="portfolio">
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">POSTA - Artistic Poster Generation</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[arXiv]</strong> Haoyu Chen</span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">Artistic Poster Generation &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/2104.09497.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                      <a href="https://github.com/haoyuc/A2N"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">   &nbsp; <strong>[Code]</strong></a>
                 
                




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2024</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/POSTA/assets/img/AAN.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">Among recent advances in SISR, attention mechanisms are crucial for high performance SR models. However, few works really discuss why attention works and how it works. In this work, we attempt to quantify and visualize the static attention mechanisms and show that not all attention modules are equally beneficial. We then propose attention in attention network (AN) for highly accurate image SR. This allows attention modules to specialize to beneficial examples without otherwise penalties and thus greatly improve the capacity of the attention network with little parameter overhead.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/2104.09497.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">Low-Res Leads the Way</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[arXiv]</strong> Haoyu Chen</span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">Super Resolution &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/2104.09497.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                      <a href="https://github.com/haoyuc/A2N"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">   &nbsp; <strong>[Code]</strong></a>
                 
                




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2024</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/POSTA/assets/img/AAN.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">Among recent advances in SISR, attention mechanisms are crucial for high performance SR models. However, few works really discuss why attention works and how it works. In this work, we attempt to quantify and visualize the static attention mechanisms and show that not all attention modules are equally beneficial. We then propose attention in attention network (AN) for highly accurate image SR. This allows attention modules to specialize to beneficial examples without otherwise penalties and thus greatly improve the capacity of the attention network with little parameter overhead.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/2104.09497.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">Low-Res Leads the Way</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[arXiv]</strong> Haoyu Chen</span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">Super Resolution &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/2104.09497.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                      <a href="https://github.com/haoyuc/A2N"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">   &nbsp; <strong>[Code]</strong></a>
                 
                




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2024</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/AAN.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">Among recent advances in SISR, attention mechanisms are crucial for high performance SR models. However, few works really discuss why attention works and how it works. In this work, we attempt to quantify and visualize the static attention mechanisms and show that not all attention modules are equally beneficial. We then propose attention in attention network (AN) for highly accurate image SR. This allows attention modules to specialize to beneficial examples without otherwise penalties and thus greatly improve the capacity of the attention network with little parameter overhead.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/2104.09497.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">Snow Removal in Video</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[arXiv]</strong> Haoyu Chen, Jinjin Gu, Zhi Zhang </span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">Super Resolution &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/2104.09497.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                      <a href="https://github.com/haoyuc/A2N"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">   &nbsp; <strong>[Code]</strong></a>
                 
                




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2023</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/AAN.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">Among recent advances in SISR, attention mechanisms are crucial for high performance SR models. However, few works really discuss why attention works and how it works. In this work, we attempt to quantify and visualize the static attention mechanisms and show that not all attention modules are equally beneficial. We then propose attention in attention network (AN) for highly accurate image SR. This allows attention modules to specialize to beneficial examples without otherwise penalties and thus greatly improve the capacity of the attention network with little parameter overhead.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/2104.09497.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">RestoreAgent</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[arXiv]</strong> Haoyu Chen</span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">RestoreAgent  &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/2104.09497.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                      <a href="https://github.com/haoyuc/A2N"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">   &nbsp; <strong>[Code]</strong></a>
                 
                




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2018</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/AAN.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">Among recent advances in SISR, attention mechanisms are crucial for high performance SR models. However, few works really discuss why attention works and how it works. In this work, we attempt to quantify and visualize the static attention mechanisms and show that not all attention modules are equally beneficial. We then propose attention in attention network (AN) for highly accurate image SR. This allows attention modules to specialize to beneficial examples without otherwise penalties and thus greatly improve the capacity of the attention network with little parameter overhead.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/2104.09497.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
</div>

<div class="pagination">
  
  
    <a href="/portfolio/page2/" class="right next">Next</a>
  

  <span>1</span>
</div>



    </main>

    <footer>
      <span>
        &copy; <time datetime="2025-04-23 16:50:55 +0800">2025</time> Haoyu Chen.



      <!-- Default Statcounter code for Haoyu Chen http://chenhaoyu.com -->
<!--       <script type="text/javascript">
      var sc_project=12491342; 
      var sc_invisible=0; 
      var sc_security="c00ed0d4"; 
      var sc_https=1; 
      var scJsHost = "https://";
      document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
      "statcounter.com/counter/counter.js'></"+"script>");
      </script> -->
      <!-- <noscript> -->
      &emsp;
      <img  style="display:inline !important; margin: auto;"
      src="https://c.statcounter.com/12491342/0/c00ed0d4/0/" alt="Web
      Analytics" >
      <!-- </noscript> -->
      <!-- End of Statcounter Code -->      

      </span>



    </footer>
  </body>
</html>
