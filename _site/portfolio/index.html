<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Haoyu Chen</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" type="text/css" href="/assets/css/fontawesome-all.min.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon.ico">

  <!-- Google Analytics -->
  

</head>


  <body>
    <!-- <nav class="nav">
      <div class="nav-container">
        <a href="/">
          <h2 class="nav-title">Haoyu Chen</h2>
        </a>
        <ul>
          <li><a href="/">About</a></li>
          <li><a href="/portfolio/">Publication</a></li>
        </ul>
     </div>
   </nav> -->

    <main>
      <div class="portfolio">
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">Snow Removal in Video: A New Dataset and A Novel Method</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[arXiv]</strong> Haoyu Chen, Jinjin Gu, Zhi Zhang </span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">Super Resolution &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/2104.09497.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                      <a href="https://github.com/haoyuc/A2N"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">   &nbsp; <strong>[Code]</strong></a>
                 
                




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2023</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/AAN.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">Among recent advances in SISR, attention mechanisms are crucial for high performance SR models. However, few works really discuss why attention works and how it works. In this work, we attempt to quantify and visualize the static attention mechanisms and show that not all attention modules are equally beneficial. We then propose attention in attention network (AN) for highly accurate image SR. This allows attention modules to specialize to beneficial examples without otherwise penalties and thus greatly improve the capacity of the attention network with little parameter overhead.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/2104.09497.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">Attention in Attention Network for Image Super-Resolution</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[arXiv]</strong> Haoyu Chen, Jinjin Gu, Zhi Zhang </span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">Super Resolution &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/2104.09497.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                      <a href="https://github.com/haoyuc/A2N"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">   &nbsp; <strong>[Code]</strong></a>
                 
                




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2021</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/AAN.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">Among recent advances in SISR, attention mechanisms are crucial for high performance SR models. However, few works really discuss why attention works and how it works. In this work, we attempt to quantify and visualize the static attention mechanisms and show that not all attention modules are equally beneficial. We then propose attention in attention network (AN) for highly accurate image SR. This allows attention modules to specialize to beneficial examples without otherwise penalties and thus greatly improve the capacity of the attention network with little parameter overhead.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/2104.09497.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">PIPAL: a Large-Scale Image Quality Assessment Dataset for Perceptual Image Restoration</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[ECCV 2020]</strong> Jinjin Gu, Haoming Cai, Haoyu Chen, Xiaoxin Ye, Jimmy S.Ren, Chao Dong </span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">Image Quality Assessment, Image Restoration, Dataset &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/2007.12142.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                      <a href="https://github.com/HaomingCai/PIPAL-Codebase"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">   &nbsp; <strong>[Code]</strong></a>
                 
                
                      <a href="https://www.jasongt.com/projectpages/pipal.html"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[Project]</strong></a>
                 




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2020</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/PIPAL.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">The Image Quality Assessment (IQA) methods are developed to measure the perceptual quality of images. However, while new algorithms have been continuously improving image restoration performance, we notice an increasing inconsistency between quantitative results and perceptual quality. In this paper, we contribute a new large-scale IQA dataset and build benchmarks for IQA methods.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/2007.12142.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
    <div  class="portfolio-item">
      <div>
        <h1 class="portfolio-title">Super Resolution Perception of Industrial Sensor Data</h1>
        <div class="portfolio-line"></div>

        <div class="portfolio-content"> 
          <span class="portfolio-icon">
              <i class="fa fa-sticky-note"></i><span class="portfolio-icon-text"><strong>[arXiv]</strong> Jinjin Gu, Haoyu Chen, Guolong Liu, Gaoqi Liang, Xinlei Wang, Junhua Zhao</span>
          </span>
          </br>
          <span class="portfolio-icon">
              <i class="fa fa-tags"></i><span class="portfolio-icon-text">Super Resolution &emsp; </span>


                
                      <a href="https://arxiv.org/pdf/1809.06687.pdf"  style="color:#478ac9 !important;font-family: 'Open Sans', sans-serif;">  &nbsp; <strong>[PDF]</strong></a>
                 
                
                




          </span>
          </br>
        <!--   <span class="portfolio-icon">
              <i class="fa fa-calendar-alt"></i><span class="portfolio-icon-text">2018</span>
          </span>   -->        
        </div>

        <div id="content">
            <img src=../assets/img/SRP.jpg style="max-width:37%;max-height:180px;min-width:180px;margin-right: 5%;float:left;">
            <p style="font-size: 13px;">We propose a novel machine learning problem â€“ the SRP problem as reconstructing high-quality data from unsatisfactory sensor data in industrial systems. A case study which performs SRP on smart meter data is then presented. A network, namely SRPNet, is proposed to generate high-frequency load data from low-frequency data. This technology makes it possible to empower existing industrial facilities without upgrading existing sensors or deploying additional sensors.</p>
          </div>
                         <!--  
                      <a href="https://arxiv.org/pdf/1809.06687.pdf" >[PDF]</a>
                  -->

      </div>
    </div>
    </br>
  
</div>

<div class="pagination">
  
  

  <span>1</span>
</div>



    </main>

    <footer>
      <span>
        &copy; <time datetime="2023-08-18 01:58:51 +0800">2023</time> Haoyu Chen.



      <!-- Default Statcounter code for Haoyu Chen http://chenhaoyu.com -->
<!--       <script type="text/javascript">
      var sc_project=12491342; 
      var sc_invisible=0; 
      var sc_security="c00ed0d4"; 
      var sc_https=1; 
      var scJsHost = "https://";
      document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
      "statcounter.com/counter/counter.js'></"+"script>");
      </script> -->
      <!-- <noscript> -->
      &emsp;
      <img  style="display:inline !important; margin: auto;"
      src="https://c.statcounter.com/12491342/0/c00ed0d4/0/" alt="Web
      Analytics" >
      <!-- </noscript> -->
      <!-- End of Statcounter Code -->      

      </span>



    </footer>
  </body>
</html>
